---
title: "GitHub Copilot AgentモードでARCoreアプリ開発：Claude Sonnet 4 vs GPT-4.1"
emoji: "🐡"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [ai, githubcopilot, arcore, claude, chatgpt]
published: true
publication_name: "hololab"
---

こんにちは！この記事では、GitHub Copilotの**Agentモード**を使って、ARCoreを用いたAndroidアプリを開発する際に、**Claude Sonnet 4**と**GPT-4.1**という2つの異なるモデルでどのような差が出るのかを比較検証した結果をお届けします。

## **はじめに：GitHub Copilot Agentモードとは？**

GitHub Copilot Agentモードは、単なるコード補完を超えて、より対話的に、プロジェクト全体を見据えた開発支援を行ってくれる機能です。まるでペアプログラマーのように、仕様の相談から実装、デバッグまで幅広くサポートしてくれます。

今回は、このAgentモードの「頭脳」となるモデルを変更することで、開発体験や生成されるコードにどのような違いが生まれるのかを探ってみました。

## **なぜこの2つのモデルを選んだのか？**

今回比較対象として選んだのは、以下の2つのモデルです。

* **Claude Sonnet 4:** Anthropic社から最近発表された最新モデルの一つです。有料プランでの利用となりますが、その性能に期待して選択しました。  
* **GPT-4.1:** OpenAI社のモデルで、GitHub Copilotで**無料**で利用できるオプションとして選びました。手軽に試せるのが魅力です。

## **実験：ARCoreで平面を検知するアプリを作る**

今回の実験では、ARCoreを用いて、スマートフォンのカメラで周囲の**平面（床や壁など）を検知**し、検知した平面を画面上に表示する簡単なアプリを作成することを**目標**としました。

具体的な手順は以下の通りです。

1. **Android Studioで新規プロジェクトを作成:** まずは、まっさらなAndroidアプリのプロジェクトを用意します。  
2. **GitHub Copilot Agentモードを起動:** プロジェクトに対してAgentモードを起動し、開発の指示を出します。

### **Agentモードへの指示（プロンプト）**

各モデルに対して、以下のような趣旨の指示を出しました。

```
このプロジェクトはAndroidのプロジェクトです。
このプロジェクトをARCoreを用いて平面検知して、平面にSurfaceを表示するアプリに変更してください。
```

## **結果比較：衝撃の展開！？**

さて、それぞれのモデルに指示を出してアプリ開発を進めてもらった結果、驚くべき差が出ました。

### **GPT-4.1の場合**

* **ビルドエラーの嵐:** まず、生成されたコードのビルドが通りません。Agentモードとの対話を繰り返し、何度も修正を試みましたが、次から次へとエラーが発生しました。  
* **起動時エラーも多発:** なんとかビルドが通るようになっても、今度はアプリを起動するとクラッシュしてしまいます。これもまた、何度もデバッグと修正を繰り返す必要がありました。  
* **結果は真っ黒な画面:** 苦労の末にようやくアプリが起動するところまでたどり着きましたが、表示されたのは**真っ黒な画面**だけ。ARCoreが機能している様子はなく、平面検知どころではありませんでした。

正直なところ、GPT-4.1との開発は非常に困難を極め、最終的に目標とするアプリを完成させることはできませんでした。

### **Claude Sonnet 4の場合**

* **ビルド一発成功:** GPT-4.1での苦労が嘘のように、Claude Sonnet 4が生成したコードは**一発でビルドに成功**しました！これは非常に驚きでした。  
* **アプリ起動OK、平面検知も成功:** アプリを起動すると、カメラプレビューが表示され、ARCoreが正常に動作を開始しました。スマートフォンを動かすと、**床や机の表面が平面として検知**され、画面上に表示されました！  
* **惜しい点：カメラ画像の向き:** ほぼ完璧に見えましたが、一つだけ問題がありました。表示される**カメラ画像の向きが回転**してしまっていました。平面は検知できているだけに、この点は少し残念でした。

https://x.com/fit51/status/1926625551659188272

## **まとめ：Agentモードとモデル選びの重要性**

GitHub Copilot Agentモードは非常に強力なツールですが、その性能は**基盤となるモデルに大きく依存する**ことが今回の実験で明らかになりました。

もちろん、プロンプトの与え方や、Agentモードとの対話の進め方によって結果は変わる可能性はありますが、今回の実験では明確な差が出ました。

特に、専門的なライブラリや複雑な機能を実装しようとする場合、**より高性能なモデル（現状ではClaude Sonnet 4など）を選択する**ことで、開発効率が劇的に向上する可能性があります。もちろん、有料であるという点は考慮する必要がありますが、開発時間の大幅な短縮を考えれば、十分に投資価値はあるかもしれません。

GPT-4.1は、簡単なタスクや、すでにある程度コードが存在するプロジェクトのリファクタリングなどでは有用かもしれませんが、ゼロから複雑なアプリを構築するには、まだ改善の余地がありそうです。

今回のカメラの向きの問題については、Claude Sonnet 4に追加で指示を出して修正を試みるなど、今後の課題としたいと思います。

この記事が、皆さんのGitHub Copilot Agentモード活用の参考になれば幸いです！