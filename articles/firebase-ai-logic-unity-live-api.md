---
title: "Firebase AI Logic for Unityï¼šLive APIå®Ÿè£…ã‚¬ã‚¤ãƒ‰ã€€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±ã‚’å®Ÿç¾ã™ã‚‹"
emoji: "ğŸ¤"
type: "tech"
topics: ["firebase", "unity", "ai", "gemini", "live-api"]
published: false
publication_name: "hololab"
---

## ã¯ã˜ã‚ã«

Firebase AI Logic for Unityã‚·ãƒªãƒ¼ã‚ºç¬¬4å¼¾ï¼ä»Šå›ã¯**Live API**ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±æ©Ÿèƒ½ã®å®Ÿè£…æ–¹æ³•ã‹ã‚‰ç¶™ç¶šä¼šè©±ã®å®Ÿç¾ã¾ã§è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

å‰å›ã¾ã§ã®è¨˜äº‹ï¼š
- [ç¬¬1å¼¾ï¼šFirebase AI Logic for Unityç™ºè¡¨ï¼Geminiã§XRä½“é¨“ã‚’é©æ–°ã™ã‚‹](https://zenn.dev/hololab/articles/firebase-ai-logic-unity-androidxr)
- [ç¬¬2å¼¾ï¼šç’°å¢ƒæ§‹ç¯‰ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œã¾ã§](https://zenn.dev/hololab/articles/firebase-ai-logic-unity-sample-tutorial)
- [ç¬¬3å¼¾ï¼šç”»åƒç”Ÿæˆãƒ»ç”»åƒè§£æã®å®Ÿè£…ã¨æ¤œè¨¼](https://zenn.dev/hololab/articles/firebase-ai-logic-unity-image-generation-analysis)

Live APIã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å¾“æ¥ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã§ã¯ãªãã€**åŒæ–¹å‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡**ã«ã‚ˆã‚‹ã‚ˆã‚Šè‡ªç„¶ãªéŸ³å£°å¯¾è©±ä½“é¨“ã‚’Unityã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆã§ãã¾ã™ã€‚

## æœ¬è¨˜äº‹ã§æ‰±ã†å†…å®¹

### Live APIæ©Ÿèƒ½
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±**: ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã§ã®åŒæ–¹å‘éŸ³å£°é€šä¿¡
- **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ**: ãƒ†ã‚­ã‚¹ãƒˆãƒ»éŸ³å£°ã®åŒæ™‚å…¥å‡ºåŠ›
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†**: WebSocketãƒ™ãƒ¼ã‚¹ã®ç¶™ç¶šçš„ãƒ‡ãƒ¼ã‚¿äº¤æ›

### å®Ÿè£…ä¸Šã®èª²é¡Œã¨è§£æ±ºæ–¹æ³•
- **ç¶™ç¶šä¼šè©±ã®å®Ÿç¾**: ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¯¾ç­–ã¨è‡ªå‹•å†æ¥ç¶š
- **å®‰å®šã—ãŸéŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰**

## Live APIã®ç‰¹å¾´ã¨åˆ¶é™äº‹é …

### å¯¾å¿œãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
ç¾åœ¨ã®Live APIã‚µãƒãƒ¼ãƒˆçŠ¶æ³ï¼š
- **ã‚µãƒãƒ¼ãƒˆæ¸ˆã¿**: Androidã€Flutterã€Unity
- **è¿‘æ—¥æä¾›äºˆå®š**: Apple ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€Web ã‚¢ãƒ—ãƒª

### APIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¦ä»¶
**é‡è¦**: Live APIã¯**Vertex AI Gemini API**ã®ã¿ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚
- **å¯¾å¿œ**: Vertex AI Backend
- **è¿‘æ—¥æä¾›äºˆå®š**: Gemini Developer API

### ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œçŠ¶æ³
- **ç¾åœ¨å¯¾å¿œ**: ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°
- **è¿‘æ—¥æä¾›äºˆå®š**: å‹•ç”»å…¥åŠ›ï¼ˆæœŸå¾…ã—ã¦ã„ãŸæ©Ÿèƒ½ã§ã™ãŒã€ã¾ã åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### æŠ€è¡“ä»•æ§˜
- **éŸ³å£°å…¥åŠ›å½¢å¼**: Raw 16 bit PCM audio at 16kHz little-endian
- **éŸ³å£°å‡ºåŠ›å½¢å¼**: Raw 16 bit PCM audio at 24kHz little-endian
- **é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«**: WebSocket
- **æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**: `gemini-2.0-flash-live-preview-04-09`

### åˆ©ç”¨åˆ¶é™
- **åŒæ™‚ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: Firebaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚ãŸã‚Š10ã‚»ãƒƒã‚·ãƒ§ãƒ³
- **ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™**: æ¯åˆ†4Mãƒˆãƒ¼ã‚¯ãƒ³
- **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³é•·**: 30åˆ†
- **ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆ**: å¾Œæ–¹äº’æ›æ€§ã®ãªã„å¤‰æ›´ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™

## æ¤œè¨¼ç’°å¢ƒ

- **Unity**: 6000.0.44f1
- **Firebase Unity SDK**: 12.9.0
- **å¯¾è±¡ãƒ¢ãƒ‡ãƒ«**: `gemini-2.0-flash-live-preview-04-09`
- **ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **: Android
- **éŸ³å£°è¨­å®š**: Prebuilt Voice "Puck"

## 1. Live APIã®åŸºæœ¬å®Ÿè£…

### LiveGenerativeModelã®ä½œæˆ

Live APIã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®åŸºæœ¬çš„ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼š

```csharp
// Live APIã¯Vertex AI Backendã®ã¿ã‚µãƒãƒ¼ãƒˆ
var backend = FirebaseAI.Backend.VertexAI();

// éŸ³å£°å°‚ç”¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
var config = new LiveGenerationConfig(
  responseModalities: new[] { ResponseModality.Audio },
  speechConfig: SpeechConfig.UsePrebuiltVoice("Puck")
);

var model = FirebaseAI.GetInstance(backend).GetLiveModel(
  modelName: "gemini-2.0-flash-live-preview-04-09",
  liveGenerationConfig: config
);
```

### ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ã¨éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

Live APIã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç¢ºç«‹ã¨åŒæ–¹å‘éŸ³å£°é€šä¿¡ï¼š

```csharp
// ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
var session = await model.ConnectAsync();

// éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ï¼ˆä¾‹ï¼šãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‹ã‚‰ï¼‰
await session.SendAudioAsync(audioData);

// éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡
await foreach (var response in session.ReceiveAsync())
{
  if (response.AudioAsFloat != null)
  {
    // å—ä¿¡ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã§å†ç”Ÿ
    foreach (var audioChunk in response.AudioAsFloat)
    {
      // audioChunkã‚’AudioSourceã§å†ç”Ÿ
      PlayAudioChunk(audioChunk);
    }
  }
  
  if (response.Text != null)
  {
    Debug.Log("AI Response: " + response.Text);
  }
}
```

### å®Œå…¨ãªUnityå®Ÿè£…ä¾‹

```csharp
using Firebase.AI;
using System.Collections;
using UnityEngine;

public class LiveAudioChat : MonoBehaviour
{
  private LiveSession session;
  private AudioSource audioSource;
  private AudioClip microphoneClip;
  private bool isRecording = false;
  
  async void Start()
  {
    // Live APIãƒ¢ãƒ‡ãƒ«è¨­å®š
    var backend = FirebaseAI.Backend.VertexAI();
    var config = new LiveGenerationConfig(
      responseModalities: new[] { ResponseModality.Audio },
      speechConfig: SpeechConfig.UsePrebuiltVoice("Puck")
    );
    
    var model = FirebaseAI.GetInstance(backend).GetLiveModel(
      modelName: "gemini-2.0-flash-live-preview-04-09",
      liveGenerationConfig: config
    );
    
    // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
    session = await model.ConnectAsync();
    
    // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡é–‹å§‹
    _ = ReceiveAudioAsync();
    
    // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³éŒ²éŸ³é–‹å§‹
    StartRecording();
  }
  
  void StartRecording()
  {
    if (Microphone.devices.Length > 0)
    {
      microphoneClip = Microphone.Start(null, true, 60, 16000);
      isRecording = true;
      StartCoroutine(SendMicrophoneData());
    }
  }
  
  IEnumerator SendMicrophoneData()
  {
    int lastPosition = 0;
    float[] buffer = new float[1024];
    
    while (isRecording)
    {
      int currentPosition = Microphone.GetPosition(null);
      
      if (currentPosition != lastPosition)
      {
        int samplesToRead = currentPosition > lastPosition 
          ? currentPosition - lastPosition
          : microphoneClip.samples - lastPosition + currentPosition;
          
        if (samplesToRead > 0)
        {
          microphoneClip.GetData(buffer, lastPosition);
          
          // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Live APIã«é€ä¿¡
          float[] audioData = new float[samplesToRead];
          System.Array.Copy(buffer, 0, audioData, 0, samplesToRead);
          _ = session.SendAudioAsync(audioData);
          
          lastPosition = currentPosition;
        }
      }
      
      yield return new WaitForSeconds(0.1f);
    }
  }
  
  async Task ReceiveAudioAsync()
  {
    await foreach (var response in session.ReceiveAsync())
    {
      if (response.AudioAsFloat != null)
      {
        foreach (var audioChunk in response.AudioAsFloat)
        {
          // å—ä¿¡ã—ãŸéŸ³å£°ã‚’ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã§å†ç”Ÿ
          PlayAudioChunk(audioChunk);
        }
      }
    }
  }
  
  void PlayAudioChunk(float[] audioData)
  {
    // AudioSourceã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿã™ã‚‹å®Ÿè£…
    var clip = AudioClip.Create("Response", audioData.Length, 1, 24000, false);
    clip.SetData(audioData, 0);
    audioSource.clip = clip;
    audioSource.Play();
  }
}
```

## 2. ç¶™ç¶šä¼šè©±ã®èª²é¡Œã¨è§£æ±ºæ–¹æ³•

### ç™ºè¦‹ã—ãŸå•é¡Œ

Live APIã®å®Ÿè£…ã«ãŠã„ã¦ã€é‡è¦ãªèª²é¡Œã‚’ç™ºè¦‹ã—ã¾ã—ãŸï¼š

**å•é¡Œ**: åˆå›ã®éŸ³å£°å¯¾è©±ã¯æ­£å¸¸ã«å‹•ä½œã™ã‚‹ãŒã€2å›ç›®ä»¥é™ã®ç™ºè©±ã«å¯¾ã—ã¦AIãŒå¿œç­”ã—ãªã„

**åŸå› **: `liveSession.ReceiveAsync()`ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã€1å›ã®å¿œç­”å¾Œã«äºˆæœŸã›ãšçµ‚äº†ã—ã¦ã„ã‚‹

### è§£æ±ºæ–¹æ³•ï¼šè‡ªå‹•å†æ¥ç¶šæ©Ÿèƒ½

ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€åŸºæœ¬å®Ÿè£…ã«**ã‚»ãƒƒã‚·ãƒ§ãƒ³è‡ªå‹•å†æ¥ç¶šæ©Ÿèƒ½**ã‚’è¿½åŠ ã—ã¾ã™ï¼š

```csharp
public class LiveAudioChat : MonoBehaviour
{
  private LiveSession session;
  private AudioSource audioSource;
  private AudioClip microphoneClip;
  private bool isRecording = false;
  private bool isSessionActive = false;
  
  async Task ReceiveAudioAsync()
  {
    try
    {
      await foreach (var response in session.ReceiveAsync())
      {
        if (response.AudioAsFloat != null)
        {
          foreach (var audioChunk in response.AudioAsFloat)
          {
            PlayAudioChunk(audioChunk);
          }
        }
      }
      
      // ReceiveAsyncãƒ«ãƒ¼ãƒ—ãŒäºˆæœŸã›ãšçµ‚äº†ã—ãŸå ´åˆã®å‡¦ç†
      Debug.Log("ReceiveAsync loop ended - attempting to reconnect");
      
      if (isSessionActive)
      {
        await ReconnectSession();
      }
    }
    catch (System.Exception ex)
    {
      Debug.LogError("Error in ReceiveAudioAsync: " + ex.Message);
      
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å†æ¥ç¶šã‚’è©¦è¡Œ
      if (isSessionActive)
      {
        await ReconnectSession();
      }
    }
  }
  
  async Task ReconnectSession()
  {
    try
    {
      Debug.Log("Reconnecting Live API session...");
      
      // æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å†æ¥ç¶š
      var backend = FirebaseAI.Backend.VertexAI();
      var config = new LiveGenerationConfig(
        responseModalities: new[] { ResponseModality.Audio },
        speechConfig: SpeechConfig.UsePrebuiltVoice("Puck")
      );
      
      var model = FirebaseAI.GetInstance(backend).GetLiveModel(
        modelName: "gemini-2.0-flash-live-preview-04-09",
        liveGenerationConfig: config
      );
      
      session = await model.ConnectAsync();
      Debug.Log("Live session reconnected successfully");
      
      // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡ã‚’å†é–‹
      _ = ReceiveAudioAsync();
    }
    catch (System.Exception ex)
    {
      Debug.LogError("Failed to reconnect Live API session: " + ex.Message);
      isSessionActive = false;
      isRecording = false;
    }
  }
}
```

### å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

1. **ReceiveAsyncãƒ«ãƒ¼ãƒ—ã®ç›£è¦–**: æ­£å¸¸çµ‚äº†ã‚’æ¤œå‡ºã—ã¦è‡ªå‹•å†æ¥ç¶š
2. **ä¾‹å¤–å‡¦ç†ã§ã®å†æ¥ç¶š**: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚å†æ¥ç¶šã‚’è©¦è¡Œ
3. **ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç¢ºèª**: `isSessionActive`ã§ä¸è¦ãªå†æ¥ç¶šã‚’é˜²æ­¢
4. **å¤±æ•—æ™‚ã®å®‰å…¨åœæ­¢**: å†æ¥ç¶šã«å¤±æ•—ã—ãŸå ´åˆã¯å®Œå…¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢

### å®Œå…¨ãªå®Ÿè£…ä¾‹ï¼ˆå†æ¥ç¶šæ©Ÿèƒ½ä»˜ãï¼‰

åŸºæœ¬å®Ÿè£…ã«å†æ¥ç¶šæ©Ÿèƒ½ã‚’çµ±åˆã—ãŸå®Œå…¨ç‰ˆï¼š

```csharp
using Firebase.AI;
using System.Collections;
using UnityEngine;

public class LiveAudioChat : MonoBehaviour
{
  private LiveSession session;
  private AudioSource audioSource;
  private AudioClip microphoneClip;
  private bool isRecording = false;
  private bool isSessionActive = false;
  
  async void Start()
  {
    await InitializeSession();
  }
  
  async Task InitializeSession()
  {
    // Live APIãƒ¢ãƒ‡ãƒ«è¨­å®š
    var backend = FirebaseAI.Backend.VertexAI();
    var config = new LiveGenerationConfig(
      responseModalities: new[] { ResponseModality.Audio },
      speechConfig: SpeechConfig.UsePrebuiltVoice("Puck")
    );
    
    var model = FirebaseAI.GetInstance(backend).GetLiveModel(
      modelName: "gemini-2.0-flash-live-preview-04-09",
      liveGenerationConfig: config
    );
    
    // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
    session = await model.ConnectAsync();
    isSessionActive = true;
    
    // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡é–‹å§‹ï¼ˆå†æ¥ç¶šæ©Ÿèƒ½ä»˜ãï¼‰
    _ = ReceiveAudioAsync();
    
    // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³éŒ²éŸ³é–‹å§‹
    StartRecording();
  }
  
  // å†æ¥ç¶šæ©Ÿèƒ½ä»˜ãã®éŸ³å£°å—ä¿¡
  async Task ReceiveAudioAsync()
  {
    try
    {
      await foreach (var response in session.ReceiveAsync())
      {
        if (response.AudioAsFloat != null)
        {
          foreach (var audioChunk in response.AudioAsFloat)
          {
            PlayAudioChunk(audioChunk);
          }
        }
      }
      
      // ReceiveAsyncãƒ«ãƒ¼ãƒ—ãŒçµ‚äº†ã—ãŸå ´åˆã®è‡ªå‹•å†æ¥ç¶š
      if (isSessionActive)
      {
        await ReconnectSession();
      }
    }
    catch (System.Exception ex)
    {
      Debug.LogError("Error in ReceiveAudioAsync: " + ex.Message);
      
      if (isSessionActive)
      {
        await ReconnectSession();
      }
    }
  }
  
  async Task ReconnectSession()
  {
    try
    {
      Debug.Log("Reconnecting Live API session...");
      
      var backend = FirebaseAI.Backend.VertexAI();
      var config = new LiveGenerationConfig(
        responseModalities: new[] { ResponseModality.Audio },
        speechConfig: SpeechConfig.UsePrebuiltVoice("Puck")
      );
      
      var model = FirebaseAI.GetInstance(backend).GetLiveModel(
        modelName: "gemini-2.0-flash-live-preview-04-09",
        liveGenerationConfig: config
      );
      
      session = await model.ConnectAsync();
      Debug.Log("Live session reconnected successfully");
      
      // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡ã‚’å†é–‹
      _ = ReceiveAudioAsync();
    }
    catch (System.Exception ex)
    {
      Debug.LogError("Failed to reconnect: " + ex.Message);
      isSessionActive = false;
      isRecording = false;
    }
  }
  
  void StartRecording()
  {
    if (Microphone.devices.Length > 0)
    {
      microphoneClip = Microphone.Start(null, true, 60, 16000);
      isRecording = true;
      StartCoroutine(SendMicrophoneData());
    }
  }
  
  IEnumerator SendMicrophoneData()
  {
    int lastPosition = 0;
    float[] buffer = new float[1024];
    
    while (isRecording && isSessionActive)
    {
      int currentPosition = Microphone.GetPosition(null);
      
      if (currentPosition != lastPosition)
      {
        int samplesToRead = currentPosition > lastPosition 
          ? currentPosition - lastPosition
          : microphoneClip.samples - lastPosition + currentPosition;
          
        if (samplesToRead > 0)
        {
          microphoneClip.GetData(buffer, lastPosition);
          
          float[] audioData = new float[samplesToRead];
          System.Array.Copy(buffer, 0, audioData, 0, samplesToRead);
          _ = session.SendAudioAsync(audioData);
          
          lastPosition = currentPosition;
        }
      }
      
      yield return new WaitForSeconds(0.1f);
    }
  }
  
  void PlayAudioChunk(float[] audioData)
  {
    var clip = AudioClip.Create("Response", audioData.Length, 1, 24000, false);
    clip.SetData(audioData, 0);
    audioSource.clip = clip;
    audioSource.Play();
  }
}
```

## 3. å®Ÿç”¨çš„ãªå¿œç”¨ä¾‹

### XRç’°å¢ƒã§ã®éŸ³å£°ã‚¬ã‚¤ãƒ‰

```csharp
var systemInstruction = ModelContent.Text(
  "You are a virtual museum guide in a VR environment. " +
  "Provide detailed explanations about artworks and exhibits. " +
  "Respond in Japanese for Japanese speakers."
);
```

### ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªNPC

```csharp
var systemInstruction = ModelContent.Text(
  "You are a medieval innkeeper in a fantasy game. " +
  "Welcome travelers and provide information about the inn and local area. " +
  "Keep responses concise but immersive."
);
```

### éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ

```csharp
var systemInstruction = ModelContent.Text(
  "You are a helpful voice assistant for Unity developers. " +
  "Provide technical guidance and coding advice. " +
  "Always respond with audio output."
);
```

## ã¾ã¨ã‚

Firebase AI Logic for Unityã®Live APIã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±æ©Ÿèƒ½ã‚’Unityã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆã§ãã¾ã™ã€‚ã—ã‹ã—ã€å®Ÿè£…ã«ã¯ä»¥ä¸‹ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã™ï¼š

### æˆåŠŸã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ

1. **è‡ªå‹•å†æ¥ç¶šæ©Ÿèƒ½**: ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­ã«å¯¾ã™ã‚‹å …ç‰¢ãªå¯¾ç­–
2. **Vertex AI Backendå¿…é ˆ**: ç¾æ™‚ç‚¹ã§ã¯Vertex AIä»¥å¤–ã¯éå¯¾å¿œ

### ä»Šå¾Œã®å±•æœ›

- **Gemini Developer APIå¯¾å¿œ**: ã‚ˆã‚Šæ‰‹è»½ãªé–‹ç™ºç’°å¢ƒã®æä¾›äºˆå®š
- **å‹•ç”»å…¥åŠ›ã‚µãƒãƒ¼ãƒˆ**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ä½“é¨“ã®ã•ã‚‰ãªã‚‹æ‹¡å……
- **Appleãƒ»Webå¯¾å¿œ**: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œã®æ‹¡å¤§

Live APIã¯ç¾åœ¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆã§ã™ãŒã€XRã‚„ã‚²ãƒ¼ãƒ é–‹ç™ºã«ãŠã„ã¦éŸ³å£°ã«ã‚ˆã‚‹ãƒŠãƒãƒ¥ãƒ©ãƒ«ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã™ã‚‹å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ä»Šå¾Œã®å±•æœ›ã«æœŸå¾…ã—ã¾ã™ã€‚

---

**å‚è€ƒãƒªãƒ³ã‚¯**
- [Firebase AI Logic Live API å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://firebase.google.com/docs/ai-logic/live-api)
- [Firebase Unity SDK ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](https://firebase.google.com/docs/reference/unity/)
- [æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Fumiya-Hori-HL/FirebaseAILogic-Unity)